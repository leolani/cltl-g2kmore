# Get to know more about you

This project exploits an episodic Knowledge Graph (eKG) to drive the communication with a user to learn about his/her Activities of Daily Life (ADL), such as eating, cooking, visiting friends, watching movies, sleeping, etc. To achieve this it queries the eKG for all activities already stored and asks questions to fill any gaps between the current interaction and the last interaction, basically asking what you have been up to lately. See our reference for further explanations and motivation.

## Events
The eKG represents activities as events following the Simple Event Model (SEM). SEM events have ```sem:hasActor```, ```sem:hasPlace``` and ```sem:hasTime``` relations to entities and time points. This representation allows to create a timeline of activities in which people, things and places are involved.

The core module of this project provides functions to pursue intentions of the agent to obtain certain knowledge states. This module can be integrated in the Leolani event bus as a service to steer the interection with another agent or user.

The ```examples``` folder contains data and some script to demonstrate and analyse these functions. 

## Examples
The examples folder has some scripts to demonstrate the application:

* structured_diary/generate_events.py
* structured_diary/structured_diary.py
* structured_diary/visualise_timeline.py
* structured_diary/get_temporal_containers.py

Roughly the scripts simulate four consecutive steps:

1. Populate the eKG with activities to create a history of events
2. Querying the eKG to find gaps in this history between two timepoints
3. Asking questions to a presumed user to fill these gaps and adding statements from this presumed user to add activities upto a saturation point
4. Extract a timeline of activities for a specific period and visulise this in a plot

We will go through these example scripts below and explain the main functionality of the core module afterwards.

### Populating the eKG
The eKG can be populated in different ways. In the examples folder, we show how a synthetic life can be generated by randomly selecting types of events, participants, places and dates within a period from a given list. The events should be typed when generating for later retrieval (see the ```examples\structured_diary\genererate_events.py``` script). Alternatively, you can upload a JSON file with activities to be uploaded in the eKG. The data folder in examples has two examples: ```activities1.json``` and ```activities-2.json``` in the examples\data folder.

### Finding gaps
Given a history stored in the eKG, this module provides a function to query the eKG as an episodic memory to create a timeline of the past and next derive questions to learn about periods in which there are no or only few activities known. The ```get_temporal_containers.py``` script queries the eKG to obtain all activities from the eKG that matcn a event type or event label and splits these in three temporal containers based on the date of a date for the current and another date for the latest interaction:

* history: all activities that happened before the latest interaction
* gap: all activities in between the latest interaction and the current date
* future: all activities planned beyond the current date

Thet dates for the latest interaction and the data for the current can be set in each call of the function, determining different slices for the history, the gap and the future.

### Filling gaps
The gap is used to pro-actively prompt users to provide more information about the actiities in their life. The script ```examples\structured_diary\structured_diary.py``` queries the eKG for so-called **gaps** and ask questions to fill these with activities upto a certain saturation point. In this demo script, the asnwers to the questions from the user are simulated.

### Vislualising timelines
The script ```visualise_timeline.py``` in examples\structured_diary lets you select a period and visualise a person's timeline in a plot. The eKG allows for representing emotional, epistemic and deontic perspectives of sources on the events they are involved in. For the visualisation, these perspectives are mapped to sentiment scores on the y-axis.

## Intent modeling

The core module of this project can be used by an agent as a drive to learn more about a user upto a certain saturation level. The module can be integrated in the Leolani platform to interact with a user, where the conversation is driven by the need to fill any gaps or know more about activities. The ```src/cltl/g2kmore``` and ```src\cltl_service``` packages provide the api functions to be integrated in a Leolani application. The drive is modeled through intents at different levels granularity.

The goal of this model is to get more knowledgeable about a topic of a certain type, about you as a person or Amsterdam as a city. This drive is implemented as a higher order **INTENT** model following a Belief-Desire-Intent model. The module proceeds according to the following steps, defined in ```_take_action(target, type)```:

1. _define(target, type): defines the goals
2. _evaluate(): evaluate the status of the goal:
3. While the _state is not REACHED or GIVEUP, do:
   1. _pursue
   2. _wait
   3. _evaluate()
4. When done, _repond() the result

The goals are defined as knowledge gaps about the Target topic which is a specific Type. The Target and the Type should be known, otherwise no goal can be set. Types are predefined in the N2MU ontology. Targets are added to the graph (populating the eKG) by communicating about these as an instance of a Type. The most basic way is to introduce yourself to the agent or talk about somebody/something else. Given the Type, the agent will generate questions it could possibly know about the Target but does not. These represent the gaps of knowledge to be filled.

When evaluating, we check if all goals have been reached or we exceeded the threshold of reaching the goals (_goal_attempts_max). One subgoal will be in focus and is tried for a maximum number of times (_focus_attempt_max).

The evaluation function:

1. Checks if all gaps are filled or the number of attempts exceeded a threshold (__goal_attempts_max)
2. If not it randomly selects a gap as the _focus or continues with the current _focus unless it exceeds a threshold (_focus_attempt_max)

Although the INTENT model can be used for any type of Target and or property, we focus in the examples on activities as events. The ```achieve_goal.py``` script simulates a user interaction driven by defining a goal for the target **carl** by quering the brain for gaps and assessing if the goal is reached or the give up point is reached. The user input here is simulated by triples with a "dummy" value as the answer to the questions. The verbalization of the question is simulated through a simple replier that takes the triple that represents the gaps and verbalizing it through a template.

## Requirements
The application was created in Python 3.9. The dependencies are defined in the requirements.txt file. To get started:

1. create a virtual environment with Python 3.9 and activate the environment
2. run pip install -r requirements.txt from the command line with the environment active
3. Download and install [GraphDB](https://www.ontotext.com/products/graphdb) on your local computer
4. Define a new repository in GraphDB with the name "demo" which will act as the episodic Knowledge Graph

## Reference
P. Vossen, S. Báez Santamaría, and T. Baier, “A conversational agent for structured diary construction enabling monitoring of functioning & well-being,” in Hhai 2024: hybrid human ai systems for the social good, IOS Press, 2024, p. 315–324.
[BibTeX]
@incollection{vossen2024conversational,
title={A Conversational Agent for Structured Diary Construction Enabling Monitoring of Functioning \& Well-Being},
author={Vossen, Piek and B{\'a}ez Santamar{\'\i}a, Selene and Baier, Thomas},
booktitle={HHAI 2024: Hybrid Human AI Systems for the Social Good},
pages={315--324},
year={2024},
publisher={IOS Press}
}

This repository is a component of the [Leolani framework](https://github.com/leolani/cltl-combot).
For usage of the component within the framework see the instructions there.


## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


<!-- LICENSE -->
## License

Distributed under the MIT License. See [`LICENSE`](https://github.com/leolani/cltl-combot/blob/main/LICENCE) for more information.

<!-- CONTACT -->
## Authors

* [Thomas Baier](https://www.linkedin.com/in/thomas-baier-05519030/)
* [Selene Báez Santamaría](https://selbaez.github.io/)
* [Piek Vossen](https://github.com/piekvossen)
